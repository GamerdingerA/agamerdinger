---
title: "Session 4 - Analysis of node centrality measures"
author: Alexander Gamerdinger
date: '2023-01-01'
slug: /centrality-measures/
categories:
  - R
  - Teaching
tags:
description: 'Session on centrality measures'
summary: 'The focus of this session is on node centrality measures, or how you can find important nodes in a network. We will cover several metrics including degree centrality, betweenness centrality, closeness and eigenvector centrality.'
---

## Session 4 - Analysis of node centrality measures

This session will provide you with tools to analyze important nodes in the network. It is different from [session 2](http://localhost:4321/teaching/virksomhedsstrategi/density-and-components/), which focused on the analysis of the network structure, as we are now focusing on the node level.

Before we introduce the new measures, let us set our working directory, load `den17`, find a subset and load a network object.

```{r load, eval=FALSE, include=TRUE}

## load working directory 
setwd("")

# libs
library(data.table)
library(tidyverse)
library(igraph)
library(ggraph)
library(readxl)
library(writexl)
library(graphlayouts)
source("r/custom_functions.R")

# Load and manipulate data set --------------------------------------------
# Load
den <- read_csv("input/den17-no-nordic-letters.csv")

# we'll be looking only at corporations
den1 <- 
  den %>% 
  filter(sector == "Corporations") 

# Now, let us only select linkers
den2 <- 
  den1 %>% 
  group_by(name) %>% 
  mutate(N = n()) %>% 
  select(N, everything()) %>% 
  filter(N >1 ) 

# Let us create a graph using an incidence matrix
# Create the incidence matrix
incidence <- xtabs(formula = ~ name + affiliation, 
                   data = den2, 
                   sparse = TRUE)

# adjacency matrix
adj_c <- Matrix::t(incidence) %*% incidence

# one-mode graph 
gr <- graph_from_adjacency_matrix(adj_c, mode = "undirected") %>% 
  simplify(remove.multiple = TRUE, remove.loops = TRUE)

```

```{r setup1, include=FALSE}

# libs
library(data.table)
library(tidyverse)
library(igraph)
library(ggraph)
library(readxl)
library(writexl)
library(graphlayouts)
source("r/custom_functions.R")

# Load and manipulate data set --------------------------------------------
# Load
den <- read_csv("input/den17-no-nordic-letters.csv")

# we'll be looking only at corporations
den1 <- 
  den %>% 
  filter(sector == "Corporations") 

# Now, let us only select linkers
den2 <- 
  den1 %>% 
  group_by(name) %>% 
  mutate(N = n()) %>% 
  select(N, everything()) %>% 
  filter(N >1 ) 

# Let us create a graph using an incidence matrix
# Create the incidence matrix
incidence <- xtabs(formula = ~ name + affiliation, 
                   data = den2, 
                   sparse = TRUE)

# adjacency matrix
adj_c <- Matrix::t(incidence) %*% incidence

# one-mode graph 
gr <- graph_from_adjacency_matrix(adj_c, mode = "undirected") %>% 
  simplify(remove.multiple = TRUE, remove.loops = TRUE)

```

After we have loaded our graph object `gr` we also want to find the largest component `comp1`. We use the following code to do that.

```{r comp1, warning=FALSE}

# What are the components?
complist <- components(gr)

# Decompose graph
comps <- decompose.graph(gr)

# Create an index
index <- 
  table(complist$membership) %>% 
  as_tibble(.name_repair = make.names) %>% 
  arrange(desc(n)) %>% 
  mutate(X = as.numeric(X)) %>% 
  pull(1)

# Select the largest component
comp1 <- comps[[index[1]]] 

# plot 
comp1 %>% 
ggraph(layout='fr') + 
geom_edge_link0(color='grey', width=0.6, alpha=0.45) + 
geom_node_point(color='black', alpha=0.6)  + 
theme_graph()

```

## 4.1 Centrality measures

In this session will focus on the following centrality measures.

1.  Degree centrality, which measures the amount of direct links that a node has with others. It tells us something about the local centrality of a node and is calculated with the function `degree()`
2.  Betweenness centrality, which measures how important a given node is in connecting other pairs of nodes in the graph. It is a common measure for identifying brokers in a network and is calculated with the function `betweenness()`
3.  Closeness centrality, which measures how efficiently the entire graph can be traversed from a given node. Nodes with high closeness centrality are likely to reach the entire network more efficiently. It is calculated with the function `closeness()`
4.  Eigenvector centrality which measures how connected a node is to other influential nodes. Nodes can have high influence through being connected to a lot of other nodes with low influence, or through being connected to a small number of highly influential nodes. It is calculated with the function `eigen_centrality()`

Let us look compare the measures with each other. First, we create a table called `metrics` which contains all centrality metrics.

Second, we look at the distributions of these metrics. You are not obliged to understand this `ggplot()` code. More importantly, you see that while betweenness, degree and eigenvector centrality behave similarly, closeness is almost normally distributed.

```{r cm}


# create a table with all centrality metrics
metrics <- tibble(
  name = names(degree(comp1, mode="all")),
  degree =        degree(comp1, mode="all"),
  betweenness =   betweenness(comp1, directed=FALSE),
  closeness =     closeness(comp1, mode="all"), 
  eigen_ctr =         eigen_centrality(comp1, directed=FALSE)$vector
)

# look at the tibble 
head(metrics)

# look at the distributions
metrics %>% 
  # changing tibble format 
  pivot_longer(degree:eigen_ctr, 
               values_to = "ctr_value", 
               names_to = "ctr_names") %>% 
  # ggplot
  ggplot(aes(x = ctr_value, y = after_stat(density), group = ctr_names, )) +
  geom_histogram(bins = 20, fill = "gray70") +
  geom_density(alpha=0.4, fill = "steelblue1", color = "gray70") +
  # spreads it out to four panes 
  facet_wrap(~ctr_names, scales = "free" ) +
  theme_minimal()

```

Next, we will add some additional columns to further understand the relationship between the centrality scores. We will make a column where we include the size of the affiliation, and create a ranking system telling us the overall rank of a node by each centrality measure. Again, this code is a little advanced not meant to be reproduced by you, so just focus on the interpretation.

```{r}

# Count the number of individuals per affiliation and filter by those that are in the metrics tibble
a1 <- den %>% 
  # count the affiliations
  count(affiliation, sort = TRUE) %>% 
  # filter
  filter(affiliation %in% metrics$name) %>% 
  # rename to metge
  rename(N = n, name = affiliation)

# merge with net_metrics data set 
metrics <- 
metrics %>% 
  left_join(a1, by = "name") %>% #merge by left data.frame which is net_metrics
  select(name, N, everything())

# make measure index
m1 <- c('degree', 'betweenness', 'closeness', 'eigen_ctr')

for (i in m1) {
  metrics <- metrics %>% arrange(desc(get(i)))
  metrics <- metrics %>% mutate(!!paste0(i, "_rank") := rleid(get(i)))
}

# Making a new variable called sum_rank, and arranging the dataset by this new variable
metrics <- 
metrics %>% 
  mutate(sum_rank = degree_rank+betweenness_rank+closeness_rank+eigen_ctr_rank) %>% 
  arrange(sum_rank)

# take a look at metrics 
head(metrics)

```

After running this snipped, look at the `metircs` object with the `view()` function to further understand the association between the centrality metrics.

## 4.2 Network visualization
